\chapter{资源受限终端任务调度策略}\label{chap:task_scheduling}

\section{引言}

任务调度问题是指系统在同时接收到多个服务请求任务的时候，将这些任务合理地分配给多个智能终端上的容器进行处理，由于不同的容器所在智能终端的处理能力不同，每个容器所占用的资源也不同，导致不同的调度方案结果会有差异，需要针对在容器化智能终端协同服务场景下的一些特点来进行取舍和进一步的优化，以追求对于终端资源利用的最大化。在该任务场景下，最常见的用户需求就是实时性需求，也即要求任务能够被快速响应、快速执行、且执行结果能够快速回传给用户，因此最小化任务完成时间是任务调度问题最主要的目标。除此之外，需要考虑的因素还涉及硬件设备功耗、分布式设备负载均衡度等。

\section{相关工作}

\subsection{传统任务调度问题求解方法}

任务调度问题是NP-hard问题，已有的任务调度算法主要分为两大类，一类是基于局部贪心策略的算法，另一类是启发式的智能搜索方法。贪心策略的算法，例如优先调度任务量最重的算法，或者优先调度计算时间最短的算法，其调度结果很容易陷入局部最优解，不能够合理利用所有资源。启发式算法则是确定搜索策略，通过迭代、评价等方式，逐步逼近全局最优解。

任务调度问题是将多个任务计划到约束下的多个节点的问题。任务调度问题是一个优化问题。应用多种算法来解决任务调度问题。基于最佳资源选择 (BRS) 的算法, 如最大最小、最小、苦难等, 是解决任务调度问题的传统方法。一些元启发式算法, 如 PSO 和基于 pso 的改进算法, 是处理任务调度问题的新方法。

\subsection{启发式算法求解方法}

近年来, 对任务调度问题进行了大量的研究。随着研究的进行, 许多元启发式算法被用来处理复杂的优化问题。元启发式算法具有简单的操作和较少的开销, 能够找到全局最优。

启发式算法中，如遗传算法（Genetic Algorithm），是模拟达尔文生物进化论的自然选择和遗传学机理的生物进化过程的计算模型，通过模拟自然进化过程搜索最优解。遗传算法将一个调度方案表示为一个染色体，并利用交叉、变异等运算符实现调度方案的进化，最终得到的结果比较好，但是收敛速度较慢且运算量较大。模拟退火算法（Simulated Annealing Algorithm），仿照固体退火原理，是一种基于概率的算法，从某一较高初温出发，伴随温度参数的不断下降,结合概率突跳特性在解空间中随机寻找目标函数的全局最优解，即在局部最优解能概率性地跳出并最终趋于全局最优。Kennedy和Eberhart在1995年提出粒子群算法（Particle Swarm Optimization），该算法最初是受到飞鸟集群活动的规律性启发，进而利用群体智能建立的一个简化模型，通过追随当前搜索到的最优值来寻找全局最优。

许多元启发式算法被引入到优化问题中。GA 是戈德伯格在1988年提出的经典元启发式算法, 它将自然选择理论引入到优化过程中, 包括突变、交叉和选择 \ citefonseca1995an,Whitley1994, Tanese1989DGA, Ng广州市2018。虽然 GA 的性能相当好, 但遗传算法的操作过于复杂, 无法实现, 不适合某些情况。一些元启发式算法的灵感来自昆虫、鱼类、鸟类和其他群体生物的自然行为。粒子群算法 (PSO) 是肯尼迪1995年提出的经典元启发式算法。PSO 的原理简单, 性能显著 \ 1995年的柠檬素颗粒, Liao2007, Gomathi2013。蚁群优化算法 (ACO) 是受蚂蚁在鸟巢和食物来源之间自然觅食行为的启发。ACO 利用化学信息素在中国的人群中进行交流。

最近提出了一些新的元启发式优化算法。关于改进这些算法的研究并不多。蚂蚁狮子优化器提出 (ALO) 在2015年是受狮子 \ citemirjilili2013 蚂蚁的狩猎行为的启发。鲸鱼优化算法 (WOA) 于2016年提出。WA 模拟鲸鱼的自然狩猎行为。2016年提出的蜻蜓算法 (DA) 是受蜻蜓群在自然界中的静态和动态行为的启发。


2017年, Shahrzad Saremi 和 Seyedali Mirjalili 提出了一种新的元启发式优化算法, 称为蝗虫优化算法 (GOA)。GOA 利用群体内部的相互作用和蜂群外的风的影响来模拟蝗虫群的迁徙行为, 寻找目标食物 \ citesare2013 2017 蝗虫。GOA 算法利用群智能, 通过在蝗虫群之间分享经验, 确定搜索方向, 找到最佳或近似的最佳位置。GOA 还使用了具有多个迭代的进化方法, 以提高群智能的效率。

开发了一些基于 GOA 的改进算法。OBLGOA 是由艾哈迈德·埃维斯在2018年提出的 \ ceewees 2013 改进。根据目前的搜索位置, 引入了基于对立面的学习策略, 以生成相反的解作为候选方案。OBL 策略可以提高算法的收敛速度, 但由于缺乏随机性, 改进有限。桑卡拉阿罗拉提出了混沌蝗虫优化算法在 2018年 \ 柠檬酸乱糟糟。将混沌映射应用到算法中, 提高了 GOA 的性能。采用10幅混沌映射来评价混沌理论的影响。结果并不是特别理想, 因为混沌因素在处理许多基准函数时并不合适。提出了一种基于 GOA 的新算法来解决优化问题和任务调度问题。

\section{GOA算法}
\subsection{GOA算法背景}
\subsection{GOA算法数学模型}
蝗虫优化算法模拟蝗虫的昆虫群行为。蝗虫蜂拥而至, 远距离迁徙, 寻找一个有食物的新栖息地。在这个过程中, 蝗虫之间的互动在蜂群内部互相影响。风的力量和蜂群外的重力影响蝗虫的轨迹。食物的目标也是一个重要的影响因素。

受上述三个因素的影响, 移民过程分为勘探和开发两个阶段。在勘探阶段, 鼓励蝗虫快速、突然地移动, 寻找更多潜在的目标区域。在开发阶段, 蝗虫往往在当地移动, 以寻找更好的目标地区。蝗虫自然实现了勘探开发寻找食物来源的两种迁徙趋势。此过程可以抽象为优化问题。蝗虫群被抽象为一群搜索代理。

Seyedali Mirjalili 在文献[]中提出了蝗虫群体迁移的数学模型。具体的模拟公式如下：

\begin{equation}
    X_i = S_i + G_i + A_i 
\end{equation}

这里变量$X_i$是第i个搜索单位的位置，变量$S_i$代表蝗虫集群内部搜索单位间社会交互对第i个搜索单位的影响因子，变量$G_i$代表蝗虫集群外部重力因素对第i个搜索单位的影响因子，变量$A_i$代表风力的影响因子。变量$S_i$的定义公式如下：

\begin{equation}
    S_i = \sum_{j=1, j\neq{i}}^N s(d_{ij})\widehat{d_{ij}}
\end{equation}

这里变量$d_{ij}$代表第i个搜索单位和第j个搜索单位之间的欧式距离，计算方法如下：
\begin{equation}
    d_{ij}=|x_j-x_i|
\end{equation}

变量$\widehat{d_{ij}}$代表第i个搜索单位和第j个搜索单位之间的单位向量，计算方法如下：

\begin{equation}
    \widehat{d_{ij}}=\frac{x_j-x_i}{d_{ij}}
\end{equation}

\emph{s}是一个函数，用于计算蝗虫集群之间的社会关系影响因子，该函数定义如下：

\begin{equation}
    s(r) = fe^{\frac{-r}{l}}-e^{-r}
\end{equation}

这里\emph{e}是自然底数，变量\emph{f}代表吸引力因子，参数\emph{l}代表吸引力长度。
% where \emph{e} is the Natural Logarithm, \emph{f} represents the concentration of attraction and the parameter of \emph{l} shows the attractive length scale.
当应用于解决数学优化问题的时候，为了优化数学模型，公式1中需要加入一些适当的改动。代表集群外部影响因子的变量$G_i$和$A_i$需要被替换为目标食物的位置。这样计算公式就变成了如下的样子：

\begin{equation}
    x_i = c \Bigl(\sum_{j=1,j\neq{i}}^N c \frac{u-l}{2}s (\lvert x_j-x_i \rvert )\frac{x_j-x_i}{d_{ij}} \Bigr) + \widehat{T_d}
\end{equation}

这里参数\emph{u}和参数\emph{l}分别代表搜索空间的上界和下界。变量$\widehat{T_d}$是目标食物的位置，在优化问题的数学模型中代表所有搜索单位在整个搜索过程中所能找到的最优的解的位置。另外，参数\emph{c}是搜索单元的搜索舒适区控制参数，改变参数\emph{c}的大小可以平衡搜索过程中的“开拓”和“探索”两个阶段。参数\emph{c}的计算方式如下：

\begin{equation}
    c = cmax - iter \frac{cmax - cmin}{MaxIteration}
\end{equation}


这里参数\emph{cmax}和参数\emph{cmin}分别是参数\emph{c}的最大值和最小值，参数\emph{iter}代表当前的迭代次数，参数\emph{MaxIteration}代表最大迭代次数。

在优化问题的求解过程中，公式4作为演进公式，被不断循环迭代来寻找最优解，直到达到迭代终止条件为止。通常迭代终止条件为达到预设的最大迭代次数，或者所得到的最优解满足预设的最优解条件。在本研究所涉及到的优化问题中，迭代终止条件均为达到预设的最大迭代次数。在迭代演进的过程结束后，该算法可以得到一个近似的最优解的位置以及相应的最优解的值。

蝗虫优化算法的算法伪代码如\ref{alg:GOA}所示：
\begin{algorithm}
    % \setstretch{1.35}

    \caption{蝗虫优化算法}
    \label{alg:GOA}
    
    \begin{algorithmic}[1]
    \State initialize the swarm and set the position boundaries u and l
    \State initialize the factors including cmax, cmin, MaxIteration
    \State initialize all the search agents position with random origin matrix 
    \State calculate the target fitness and mark the target position
    
    \While {$(iter < MaxIteration$ and $target fitness > destination fitness)$}
    \State calculate $d_ij$ and $\widehat{d_ij}$ by equation(2)
    \State calculate $s(d_ij)$ by equation(3)
    \State update $x_i$ by equation(4)
    \State calculate the fitness 
    \If{current fitness is better than target fitness}
        \State update the target fitness and the target position
    \EndIf
    \State $iter = iter +1$
     
    \EndWhile

    \State Return target fitness and target position
    
    
    \end{algorithmic}
    
\end{algorithm}

\subsection{蝗虫算法优缺点分析}
GOA是最近受到蚱蜢自然迁移行为启发的元启发式算法。 虽然GOA具有简单的理论基础并且易于实现，但GOA的性能更优越。 原始的GOA改变了蚱蜢的舒适区域，这可以使目标通过迭代收敛到全局最优解。 与一些经典算法相比，GOA的收敛速度要快得多。 GOA可显着提高蝗虫的平均适应度，改善蝗虫的初始随机种群。虽然GOA具有这些优点，但它也存在一些阻碍算法获得更好解决方案的缺点。 在对GOA公式进行一些理论分析和用MATLAB代码进行的一些实验之后，给出了GOA的几个缺点。

首先，GOA使用线性递减参数使搜索过程收敛，这很难区分过程的两个阶段，即开发阶段和探索阶段。 其次，在搜索过程的早期阶段的每次迭代期间，最佳解决方案的位置急剧波动。 似乎最终的最佳解决方案只受搜索过程后期的影响，无论前一阶段的结果如何。 GOA理论无法充分利用所有搜索迭代。 当最大迭代次数增加时，GOA的最佳适应性不是很突出，例如，从实验结果中发现的500到1500。 最后，搜索过程很容易陷入局部最优。 GOA易于实现的优势无助于摆脱局部最优，这可能是GOA的劣势。


\section{带随机跳出机制的动态权重蝗虫优化算法(DJGOA)}
\subsection{动态权重}
GOA使用线性递减参数来限制搜索空间并使所有搜索代理移动到目标位置。 线性递减参数不能增强搜索过程的两个阶段的影响，即开发阶段和探索阶段。 在探索阶段，GOA无法在目标搜索区域周围快速收敛，搜索代理只是在整个搜索空间中游荡，这无法为后期搜索阶段奠定坚实的基础。 在开发阶段，参数通常使搜索代理滑过局部最佳位置，就像搜索代理超速运动一样。

线性递减参数机制无法使算法充分利用整个迭代。 引入动态权重参数机制以提高算法的利用率。 搜索进度分为三个阶段，即早期阶段，中间阶段阶段和后期阶段。 在早期阶段，目标位置的权重应该更高，以使搜索过程快速收敛。 在中间阶段，参数应该是稳定的，以使算法探索搜索空间。 在后期阶段，搜索代理中的重力的权重应该更小，以深入利用局部最优解位置。 具有动态权重参数的GOA公式表示为算法[1]。 新的迭代方程如下：

\begin{equation}
    x_i = m*c \Bigl(\sum_{j=1,j\neq{i}}^N c \frac{u-l}{2}s (\lvert x_j-x_i \rvert )\frac{x_j-x_i}{d_{ij}} \Bigr) + \widehat{T_d}
\end{equation}
where \emph{m} is the dynamic weight parameter to adjust the search process. To correspond to the feature of the three phases of the search process, the parameter \emph{m} is set as follows:
\begin{equation}
    m= \begin{cases}
        0.5-\frac{(0.5-0.1)*iter}{MaxIteration*0.2} & \quad 0<iter\leq MaxIteration*0.2 \\
        0.1&\quad MaxIteration*0.2<iter \leq MaxIteration*0.8 \\
        0.05& \quad  MaxIteration*0.8 < iter \leq MaxIteration
        \end{cases} 
\end{equation}

\subsection{随机跳出机制}

原始的GOA算法没有使用跳跃机制，并且所有搜索代理仅根据社交互动和目标食物吸引力的影响而移动。 原始GOA的机制可能导致算法陷入局部最优位置。

引入随机跳跃策略以帮助GOA算法提高跳出局部最佳位置的概率。 参数\emph{p}被设置为跳跃阈值。 在迭代结束之前，将当前最佳适合度与最后一次迭代的最佳适应度进行比较。 如果当前最佳适应度和最后一个最佳适应度的比率高于阈值\emph{p}，则可以假设该算法没有找到更好的解决方案，并且随机跳跃机制应该启动。 根据随机初始化规则在最佳位置周围生成新的搜索代理。 随机初始化规则如下：
\begin{equation}
    tempPos=curPos*((0.5-rand)*iniRan+1);
\end{equation} 
其中\emph{tempPos}是新搜索代理的位置，\emph{curPos}是当前最佳解决方案的位置。 \emph{iniRan}是管理随机跳跃边界的初始化范围参数。 如果\emph{iniRan}更高，则算法的全局搜索能力就像模拟退火算法一样得到增强。
\subsection{DJGOA算法流程}

本文提出了一种随机跳跃动态权重蝗虫优化算法（DJGOA）。 DJGOA的过程分为初始阶段，参数设置阶段，计算阶段和适应度更新阶段四个阶段。在初始化阶段，设置包括位置边界在内的一些因素，并在边界内随机初始化原始群体位置。在参数设置阶段，搜索过程进入迭代循环，动态权重参数根据当前迭代由\ emph {equation（7）}设置。在计算阶段，群体内的社会交互由\ emph {equation（6）}计算。在适应度更新阶段，如果当前适应度优于历史的最佳目标适应度，则更新目标解决方案的适合度。如果当前适应度与最后一次迭代的适应度之比高于之前设置的阈值\ emph {p}，则使用随机跳转策略生成新的搜索代理以尝试跳出局部最优位置通过\ emph {equation（8）}。具有随机跳跃的动态权重蝗虫优化算法（DJGOA）的伪代码显示为算法\ref{alg:DJGOA}。

\begin{algorithm}
    % \setstretch{1.35}

    \caption{带随机跳出机制的动态权重蝗虫优化算法}
    \label{alg:DJGOA}
    
    \begin{algorithmic}[1]
    
    \State initialize the swarm and set the position boundaries u and l
    \State initialize the factors including cmax, cmin, MaxIteration and iniRan
    \State initialize all the search agents position with random origin matrix 
    \State calculate the target fitness and mark the target position
    
    \While {$(iter < MaxIteration$ and $target fitness > destination fitness)$}
    \State set the dynamic weight parameter m by equation(7)
    \State calculate $d_ij$ and $\widehat{d_ij}$ by equation(2)
    \State calculate $s(d_ij)$ by equation(3)
    \State update $x_i$ by equation(6)
    \State calculate the fitness 
    \If{current fitness is better than target fitness}
        \State update the target fitness and the target position
    \EndIf
    \If{$(current fitness/last fitness) > p$}
        \State generate a new search agent by equation (8)
        \If{the new fitness is better than target fitness}
            \State update the target fitness and the target position
        \EndIf
    \EndIf
     
    \EndWhile

    \State Return target fitness and target position
    
    
    \end{algorithmic}
    
\end{algorithm}

\subsection{实验结果}
\subsubsection{实验设置}

为了评估所提算法的性能，进行了一系列实验。 我们将所提出的DJGOA与GOA的原始算法（最近的Dragonfly算法（DA）的元启发式算法）和粒子群算法（PSO）的经典启发式算法进行了比较，该算法通过在\ cite {saremi2017grasshopper}中使用的13个基准函数。 13个基准功能分为两种类型。 函数\ emph {f1-f7}是单峰函数，它测试了算法的收敛速度和局部搜索能力。 函数\ emph {f8-f13}是多模函数，当存在多个局部最优时，它测试算法的全局搜索能力。 表\ref{tab:unimodal_function}中列出了7个单峰测试函数的详细信息和表达式,表\ref{tab:multimodal_function}中列出了6个多峰测试函数的详细信息和表达式。
\begin{table}[!htbp]
    \centering
    \caption{F1-F7单峰测试函数}
    \label{tab:unimodal_function}
    % \small
    \renewcommand\arraystretch{1.5} 
\begin{tabular}{l c c c}
  \hline
  Function & Dim & Range & $f_{min}$ \\
  \hline
  $F_1(x)=\sum_{i=1}^n x_i^2$ & 30 & [-100,100]&0 \\
  \hline
  $F_2(x)=\sum_{i=1}^n\left|x_i\right|+\prod_{i=1}^n\left|x_i\right|$& 30 & [-10,10]&0 \\
  \hline
  $F_3(x)=\sum_{i=1}^n(\sum_{j=1}^ix_j)^2$& 30 & [-100,100] & 0\\
  \hline
  $F_4(x)=max_i\{\left|x_i\right|,1\leq i\leq n\}$& 30 & [-100,100] & 0\\
  \hline
  $F_5(x)=\sum_{i=1}^{n-1}[100(x_{i+1}-x_i^2)^2+(x_i-1)^2]$& 30 & [-30,30] & 0\\
  \hline
  $F_6(x)=\sum_{i=1}^n([x_i+0.5])^2$& 30 & [-100,100] & 0\\
  \hline
  $F_7(x)=\sum_{i=1}^n ix_i^4 + random[0,1)$& 30 & [-1.28,1.28] & 0\\
  \hline
\end{tabular}
\end{table}


\begin{table}[!htbp]
    \centering
    \caption{F8-F13多峰测试函数}
    \label{tab:multimodal_function}
    \small
    \renewcommand\arraystretch{1.5} 
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\begin{tabular}{l c c c}
    \hline
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    Function & Dim & Range & $f_{min}$ \\
    \hline
    $F_8(x)=\sum_{i=1}^n -x_i \sin(\sqrt{|x_i|})$ & 30 & [-500,500]&$-418\times Dim$ \\
    \hline
    $F_9(x)=\sum_{i=1}^n [x_i^2 - 10\cos(2\pi x_i)+10]$& 30 & [-5.12,5.12]&0 \\
    \hline
    % $F_{10}(x)=-20exp(-0.2\sqrt{\frac{1}{n}\sum _{i=1}^n x_i^2})-exp(\frac{1}{n}\sum_{i=1}^n \cos(2\pi x_i))+20+e$& 30 & [-32,32] & 0\\
    % \hline
    \tabincell{c}{$F_{10}(x)=-20exp(-0.2\sqrt{\frac{1}{n}\sum _{i=1}^n x_i^2})-$\\$exp(\frac{1}{n}\sum_{i=1}^n \cos(2\pi x_i))+20+e$}& 30 & [-32,32] & 0\\
    \hline
    $F_{11}(x)=\frac{1}{4000}\sum_{i=1}^n x_i^2 - \prod_{i=1}^n \cos(\frac{x_i}{\sqrt{i}})+1$& 30 & [-600,600] & 0\\
    \hline

    \tabincell{c}{$F_{12}(x)=\frac{\pi}{n} \{10\sin(\pi y_1)+\sum_{i=1}^{n-1} (y_i-1)^2 [1+10 \sin^2 (\pi y_{i+1} )]+ $ \\ $(y_n -1)^2\}+ \sum_{i-1}^n u(x_i,10,100,4)+\sum_{i=1}^n u(x_i,10,100,4)$\\ $y_i=1+\frac{x_i+1}{4}$ \\$u({x_i},a,k,m) = \left\{ \begin{array}{l}k{({x_i} - a)^m}{\rm{   }}{x_i} > a\\0{\rm{                }} - a < {x_i} < a\\k{( - {x_i} - a)^m}{\rm{  }}{x_i} <  - a\end{array} \right.$ }& 30 & [-50,50] & 0\\
    \hline
    \tabincell{c}{$F_{13}(x)=0.1\{\sin^2(3\pi x_1)+\sum_{i=1}^n (x_i-1)^2[1+\sin^2(3\pi x_i+1)]+$\\$(x_n-1)^2[1+\sin^2(2\pi x_n)]\}+\sum_{i=1}^nu(x_x,5,100,4)$}& 30 & [-50,50] & 0\\
    \hline
    
  \end{tabular}
\end{table}


为了解决测试功能，采用了30个搜索代理，最大迭代次数设置为500.每个算法的每个实验进行30次以产生统计结果。 GOA，DA和PSO的参数设置为论文引用{引用{mirjalili2016dragonfly}引用文件。\ citemi2017grasshopper}。

% 这里可能要加一下测试参数，包括算法参数设置、agents数量和迭代次数等等

\subsubsection{实验结果}
表\ref{tab:DJGOA_computation_result}中给出了30次实验的平均值，标准偏差，最佳值和最差值，以描述DJGOA，GOA，DA和PSO的性能。
\begin{table}[!htbp]
    \centering
    \caption{DJGOA算法在13个测试函数上的实验结果}\label{tab:DJGOA_computation_result}
    % \scriptsize
    \small
    \renewcommand\arraystretch{1.3} 
    \begin{tabular}{*{9}{c}}
    % \toprule
    \hline
    测试函数& 类型&DJGOA&GOA&DA&PSO\\
    \hline
\multirow{4}*{F1}& avg& \textbf{1.66E-46}& \textbf{1.36E-07}&0.0808&0.2256\\
    & std& \textbf{9.08E-46} & \textbf{1.79E-07}&0.1056&0.2380    \\
    & best&\textbf{5.89E-68}&\textbf{3.13E-09}&0&0.0139    \\
    & worst& \textbf{4.97E-45}&\textbf{9.43E-07}&0.4929&1.1528 \\
    \hline
\multirow{4}*{F2}& avg& \textbf{1.11E-32}&\textbf{6.58E-05}&0.0686&0.0737\\
    & std&\textbf{3.28E-32}&\textbf{3.38E-05}&0.0586&0.0322   \\
    & best&\textbf{6.61E-44}&\textbf{1.18E-05}&0&0.0187  \\
    & worst&\textbf{1.54E-32}&0.0002&0.2913&0.1847 \\
    \hline
\multirow{4}*{F3}& avg&\textbf{6.32E-26}&\textbf{1.67E-06}&0.3440&0.9667\\
    & std&\textbf{3.46E-25}&\textbf{2.33E-06}&0.7516&0.6671 \\
    & best&\textbf{1.62E-56}&\textbf{4.45E-08}&0.0003&0.0395  \\
    & worst&\textbf{1.90E-24}&\textbf{1.16E-05}&3.9916&2.9592   \\
    \hline
\multirow{4}*{F4}& avg&\textbf{4.19E-19}&0.0003&0.2142&0.4936\\
    & std&\textbf{1.72E-18}&0.0002&0.1760&0.2202  \\
    & best&\textbf{1.49E-29}&\textbf{7.97E-05}&0&0.1757  \\
    & worst&\textbf{9.24E-18}&0.0009&0.6817&1.0899   \\
    \hline
\multirow{4}*{F5}& avg&9.7473&174.70&131.64&9.9186\\
    & std&40.35&387.13&308.88&7.7555  \\
    & best&0.2213&0.1492&0.2252&2.3098  \\
    & worst&221.79&1791.14&1537.62&35.84  \\
    \hline
\multirow{4}*{F6}& avg&\textbf{2.99E-10}&\textbf{1.23E-07}&0.1160&0.2246\\
    & std&\textbf{3.72E-10}&\textbf{1.05E-07}&0.1381&0.2220  \\
    & best&\textbf{1.45E-11}&\textbf{4.05E-09}&\textbf{1.13E-05}&0.0341  \\
    & worst& \textbf{1.66E-09}&\textbf{3.99E-07}&0.5918&0.8912  \\
    \hline
\multirow{4}*{F7}& avg& 0.0072&0.0012&0.0018&0.0012\\
    & std&0.0054&0.0011&0.0011&0.0008  \\
    & best&0.0005&0.0001&0.0002&0.0002 \\
    & worst&0.0203&0.0065&0.0044&0.0031  \\
    \hline
\end{tabular}
\end{table}
\begin{table}[!htbp]
    \ContinuedFloat% continue splited float
    \centering
    \caption{续表：DJGOA算法在13个测试函数上的实验结果}\label{tab:DJGOA_computation_result}
    % \scriptsize
    \small
    \renewcommand\arraystretch{1.3} 
    \begin{tabular}{*{9}{c}}
    % \toprule
    \hline
\multirow{4}*{F8}& avg& -1641&-1835&-1951&-1889\\
    & std&239.3&226.0&206.5&203.5 \\
    & best&-2297&-2297&-2394&-2178\\
    & worst&-1191&-1348&-1566&-1431 \\
    \hline
\multirow{4}*{F9}& avg& 6.1063&9.1868&5.7839&2.9096\\
    & std&9.9879&7.4073&4.5795&1.4782 \\
    & best&0&1.9899&1.0143&0.5192 \\
    & worst&34.9422&32.8334&17.9153&6.0775 \\
    \hline
\multirow{4}*{F10}& avg& \textbf{1.48E-15}&0.9446&0.5148&0.3506\\
    & std&\textbf{1.35E-15}&3.5846&0.5990&0.2632 \\
    & best&\textbf{8.88E-16}&\textbf{9.25E-05}&\textbf{7.99E-15}&0.0759\\
    & worst&\textbf{4.44E-15}&19.5869&1.9511&1.2182 \\
    \hline
\multirow{4}*{F11}& avg& 0.0790&0.2252&0.3789&0.3968\\
    & std&0.1171&0.1370&0.1906&0.1401 \\
    & best&0&0.0566&0&0.1692 \\
    & worst&0.4504&0.5293&0.7729&0.6960\\
    \hline
\multirow{4}*{F12}& avg& \textbf{8.56E-11}&\textbf{3.99E-08}&0.0430&0.0043\\
    & std&\textbf{9.30E-11}&\textbf{3.08E-08}&0.1052&0.0055 \\
    & best&\textbf{3.76E-12}&\textbf{9.10E-09}&0.0001&0.0001 \\
    & worst&\textbf{4.53E-10}&\textbf{1.30E-07}&0.5282&0.0216 \\
    \hline
\multirow{4}*{F13}& avg& \textbf{3.22E-10}&0.0011&0.0238&0.0248\\
    & std&\textbf{4.13E-10}&0.0034&0.0369&0.0225 \\
    & best&\textbf{1.91E-11}&\textbf{6.37E-09}&\textbf{9.97E-05}&0.0033 \\
    & worst&\textbf{1.66E-09}&0.0110&0.1527&0.1170 \\
    \hline
    % \bottomrule
    \end{tabular}
    \end{table}
从表\ref{tab:DJGOA_computation_result}可以看出，DJGOA的性能优于其他3种算法。 所有13个基准函数的10个结果表明，DJGOA的平均值比其他几个数量级的表现要好。 而对于其他三个测试功能的结果，DJGOA的表现略差于其他测试功能。 实际上，DJGOA可以通过GOA，DA和PSO获得相同数量级的结果。 对于上面提到的三个测试功能中的两个，DJGOA可以在获得最佳价值方面做得更好。 实验结果表明，DJGOA在标准偏差和最差值方面表现较好，表明DJGOA在搜索中更稳定。 对于12个实验结果，DJGOA可以获得更好的最佳值结果，这意味着DJGOA能够比其他3种算法更好地找到最佳适应度。  
%  一共13个测试函数，有10个结果都表明DJGOA结果更好，另外3个得到的结果也是同一数量级的，可以说是持平，而且其中的两个的best值DJGOA也是远远领先的。

对于单峰测试功能，GOA的性能非常好，DJGOA可以大大提高GOA的性能。 DJGOA将搜索结果提高了几个数量级。 对于多模式测试功能，DJGOA可以帮助算法提高很多，特别是在寻找更准确的目标适应度时。 总之，跳跃策略可以帮助算法进行大量的搜索，并且DJGOA在全局搜索和本地搜索中具有比DA，GOA和PSO更好的搜索最佳能力。

% 综上，可以说明DJGOA有更优秀的搜索能力，在全局搜索和局部搜索两个方面。这里可以证明跳出机制的优势

% 有更大幅度提升， 提高了好几个数量级。 标准差表示更加稳定。更容易找到更优秀的解，找到的最差解也相对更优。


% 附一组30次测试结果的排序图，更直观说明整体效果更优秀？这里是否放图再考虑吧

\subsubsection{威尔科克森符号秩和检验}
% 然后是p值校验，得到的结果更加可信。
进行了wilcoxon符号秩检验的实验，以验证PSO，GOA和DJGOA的置信水平。 根据表\ref{tab:wilcoxon_signed_rank_test_DJGOA}中显示的结果，13个测试函数中DJGOA的所有p值均小于0.05，这意味着得到的结论是显着的。
\begin{table}[!htbp]
    \centering
    \caption{DJGOA、GOA与PSO的威尔科克森符号秩和检验结果}
    \label{tab:wilcoxon_signed_rank_test_DJGOA}
    % \small
    \renewcommand\arraystretch{1.5} 
\begin{tabular}{c c c c || c c c c}
  \hline
  测试函数 & DJGOA & GOA & PSO &测试函数 & DJGOA & GOA & PSO\\
  \hline
  F1 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06}&F8 & \textbf{2.13E-06} & \textbf{7.51E-05}&N/A \\
  \hline
  F2 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06}&F9 & 0.8774 &\textbf{1.73E-06} &N/A \\
  \hline
  F3 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06}&F10 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06} \\
  \hline
  F4 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06}&F11 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06} \\
  \hline
  F5 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06}&F12 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06} \\
  \hline
  F6 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06}&F13 & N/A & \textbf{1.73E-06}&\textbf{1.73E-06} \\
  \hline
  F7 & \textbf{2.56E-06} & N/A&0.0082&  &   &  &  \\
  \hline
  
  \hline
\end{tabular}
\end{table}


\subsubsection{Convergence Analysis}
% 这里可以证明动态参数能够充分利用迭代，提高收敛速度
所有13个基准函数的DA，GOA和DJGOA迭代的最佳适应值的结果如图[？]所示。 收敛曲线表明，DJGOA可以使搜索过程比其他过程更快地收敛，结果也表明动态加权机制可以帮助原始GOA算法充分利用每次迭代。


\begin{figure}[!htbp]
    \centering
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{oaspl_a}
      \caption{}
      \label{fig:oaspl_a}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{oaspl_b}
      \caption{}
      \label{fig:oaspl_b}
    \end{subfigure}
    \\% line break
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{oaspl_c}
      \caption{}
      \label{fig:oaspl_c}
    \end{subfigure}%
    ~% add desired spacing
    \begin{subfigure}[b]{0.35\textwidth}
      \includegraphics[width=\textwidth]{oaspl_d}
      \caption{}
      \label{fig:oaspl_d}
    \end{subfigure}
    \bicaption{总声压级。(a) 这是子图说明信息，(b) 这是子图说明信息，(c) 这是子图说明信息，(d) 这是子图说明信息。}{OASPL.(a) This is the explanation of subfig, (b) This is the explanation of subfig, (c) This is the explanation of subfig, (d) This is the explanation of subfig.}
    \label{fig:oaspl}
\end{figure}
\section{改进蝗虫优化算法(IGOA)}
\subsection{蝗虫算法不足之处}
GOA具有简单的理论基础，易于实施。 另一方面，它有一些阻碍算法获得更好解决方案的缺点。
线性减小的舒适区无法帮助原始的GOA充分利用每次迭代。 由于缺乏随机因素，原始算法几乎没有变化。 该算法很容易陷入局部最优。为了解决这些不足，引入了三个改进：非线性舒适区参数，基于$ L \ acute {e} vy $ flight的局部搜索机制和随机跳跃策略。 本部分明确描述了这三项改进的细节。
\subsection{非线性舒适区控制参数}
原始GOA改变了舒适区的半径，这可以使搜索代理通过迭代收敛到全局最优解。 GOA使用comfort zone参数来限制搜索空间。 在探索阶段，舒适区参数应足够大，以使搜索代理获得足够的空间以快速找到近似最优。 在开发阶段，限制因素应该很小，以准确地搜索局部最优并避免搜索代理的超速运动。 然而，线性递减因子不能使搜索能力与搜索迭代期间的探索和开发阶段相协调。

为了匹配两个搜索阶段并增强算法的搜索能力，sigmoid函数被引入到这项工作中。 S形函数是常用的阈值函数和非线性调整因子。 它广泛用于信息科学领域。 sigmoid函数的公式如下所示：
\begin{eqnarray}
	f(x)=\frac{1}{1+e^{-x}}
\end{eqnarray}
基于S形函数变体的非线性舒适区参数建议如下：
% A nonlinear comfort zone parameter based on a variant of the sigmoid function is proposed as follows:
\begin{eqnarray}
    m=\frac{-0.5}{1+e^{(-1.5(cx-5)+2\sin(cx))}}+u
\end{eqnarray}
这里参数\emph{u}是调节参数，取值范围应该在[0,1]。参数\emph{cx}定义如下：
% where \emph{u} is the adjustment parameter and its value should be in the interval [0,1]. And \emph{cx} is defined as follows:
\begin{eqnarray}
	cx=\frac{v(iter+50)}{Maxiteration}
\end{eqnarray}
这里参数\emph{v}是精度调节参数，取值范围应该在[1,10]。
% where \emph{v} is the accuracy adjustment factor and its value should be in the interval [1,10].
\subsection{基于Levy飞行的局部搜索机制}
GOA的所有参数都是确定性的。 缺乏随机性可能导致搜索迭代期间缺乏创造力，并且每个搜索代理只能搜索确定的位置。 将随机因子引入确定性系统是提高其性能的常用方法。
% All the parameters of GOA are deterministic. The lack of randomness might lead to the lack of creativity during the search iterations, and every search agent could only search the determinate position. Introducing random factor to a deterministic system is a commonly used method to improve its performance.

$ L \ acute {e} vy $ flight是由Paul $ L \ acute {e} vy $ \ cite {mirjalili2016dragonfly}提出的随机搜索步骤，它是一种提供随机因子的有效数学方法。 由于$ L \ acute {e} vy $ flight实现起来非常复杂，因此如下使用模拟算法：
% $L\acute{e}vy$ flight is a random search walk proposed by Paul $L\acute{e}vy$ \cite{mirjalili2016dragonfly}, and it is an efficient mathematical method to provide a random factor. Because $L\acute{e}vy$ flight is very complicated to implement, a simulating algorithm is used here as follows:
\begin{eqnarray}
	Levy(d)=0.01\times\frac{r_1\times\sigma}{|r_2|^{\frac{1}{\beta}}}
\end{eqnarray}
where \emph{d} is the dimension of the problem, $r_1$,$r_2$ are two random numbers in [0,1] and $\beta$ is a constant number which is set to 1.5 according to Seyedali in \cite{mirjalili2016dragonfly}. $\sigma$ is calculated as follows:
\begin{eqnarray}
	\sigma=(\frac{\Gamma(1+\beta)\times \sin(\frac{\pi\beta}{2})}{\Gamma(\frac{1+\beta}{2})\time\beta\times2^(\frac{\beta-1}{2})})^\frac{1}{\beta}
\end{eqnarray}
where $\Gamma(x)=(x-1)!$.

$ L\acute{e}vy $ flight可以在所有搜索代理移动到最佳位置时为其提供视觉。 搜索代理可以看到它们周围的小区域。 为了扩展搜索代理的搜索半径并增强查找最佳值的能力，提出了一种基于$ L\acute{e}vy $ flight的本地搜索机制。 当位置更新过程结束时，应该通过$ L\acute{e}vy $航班以一定的概率调整每个搜索代理的位置。 调整公式定义如下：
% $L\acute{e}vy$ flight could give vision to all the search agents when they are moving towards the optimal position. The search agents could see the small areas around them. To expand the search radius of the search agents and enhance the ability to find the optima, a local search mechanism based on $L\acute{e}vy$ flight is proposed. When a location updating process is finished, the position of every search agent should be adjusted through $L\acute{e}vy$ flight with a certain probability. The adjustment formula is defined as follows:
\begin{eqnarray}
	X_i=X_i+10c\times s_{threshold}\times Levy(dim)\times X_i
\end{eqnarray}
where $s_{threshold}$ is the threshold parameter which control the direction and the probability of the variation. $s_{threshold}$ is calculated as follows:
\begin{eqnarray}
	s_{threshold}=sign(x_{trans}-1)+sign(x_{trans}+1)
\end{eqnarray}
where $sign(x)$ is the sign function and $x_{trans}$ is a random number in [-3,3].
\subsection{基于线性递减参数的随机跳出策略}
GOA的基本理论是基本的。 该算法只关注收敛到全局最优的过程，忽略了跳出局部最优的机制。 因此，GOA的搜索过程很容易陷入局部最优，搜索无法进一步发展。 GOA易于实现的优势无助于摆脱局部最优，这可能是GOA的劣势。
% The basic theory of GOA is elementary. The algorithm only focuses on the process of convergence to the global optimum and ignores the mechanism about jumping out of the local optimum. Hence the search process of GOA was easy to be trapped in local optimum, and the search could not go further. The advantage that GOA was simple to implement could not contribute to getting rid of the local optimum, which could be a disadvantage of GOA instead.

为了提高跳出局部最优的能力，引入了随机跳跃策略。 当搜索代理找到最佳位置时，新位置可以替换旧目标位置。 如果没有，则随机跳跃方程开始起作用。 它描述如下：
% To promote the capability to jump out of the local optimum, a random jumping strategy is introduced. When a search agent finds an optimal position, the new position can replace the old target position. When it does not, the random jumping equation is starting to work. It is described as follows:
\begin{eqnarray}
	X_i^{new}=((0.5-rand)\times 2+1)X_i 
\end{eqnarray}
where $X_i$ is the position of the \emph{i}-th search agent, and $X_i^{new}$ is the new position after random jumping. If $X_i^{new}$ has better fitness, it will replace $X_i$. Thus action of jumping out occurs successfully. 

原始GOA的演化公式仅将当前迭代获得的最佳位置作为搜索方向，并且忽略了一些其他有用信息。 为了继续新获得的跳跃动作信息的影响，将位置的演化公式转换如下：
% The evolution formula of the original GOA only takes the best position obtained by the current iteration as the search direction, and it ignores some other useful information. To continue the influence of the newly obtained information of the jumping action, the evolution formula of the location is transformed as follows:
\begin{eqnarray}
	X_i^{iter+1}=m\times c\times S_i+(1-p)\widehat{T_d}+p\times X_i^{iter}
\end{eqnarray}
其中\emph{p}是用于控制搜索代理位置影响的系数参数。 \emph{p}在第一次迭代时初始化为0。 如果搜索代理没有跳转或者无法跳出本地最佳位置，\emph{p}仍设置为0，以确保只有$ S_i $和$ T_d $才能影响进化。 当搜索代理成功跳出时，\emph{p}被设置为在三次迭代中线性递减为0的变量，以继续跳跃行为的影响。 经过一些试验，\emph{p}的递减步骤设置为0.3478，本文未对此进行讨论。 因此\emph{p}在这项工作中计算如下：
% where \emph{p} is the coefficient parameter to control the impact of the position of the search agent. \emph{p} is initialized as 0 at the first iteration. If the search agent does not jump or it fails to jump out of the local optimal location, \emph{p} is still set to 0 to make sure that the evolution can be affected only by $S_i$ and $T_d$. When the search agent jumps out successfully, \emph{p} is set to a variable linearly decreasing to 0 in three iterations to continue the influence of the behavior of jumping. After some trial, the decreasing step of \emph{p} is set to 0.3478 which is not discussed in this paper. Thus \emph{p} is calculated in this work as follows:
\begin{eqnarray}
    p= \begin{cases}
        p-0.3478 & p>0 \\
        0&p \leq 0 \\
        3\times 0.3478&when \  jumping \  out \  successfully
        \end{cases} 
\end{eqnarray}
\subsection{IGOA流程}
本文提出了一种改进的Grasshopper算法（IGOA）。 IGOA的过程分为初始阶段，演化阶段，适应性更新阶段和跳跃阶段四个阶段。
% This paper proposed an Improved Grasshopper Algorithm (IGOA). The procedure of the IGOA is divided into four stages which were the initialization stage, the evolution stage, the fitness updating stage and the jumping stage. 

在初始化阶段，设置参数，并随机初始化所有搜索代理的原始位置。此部分还计算了最佳目标位置和相应的适应度。搜索循环开始在进化阶段工作。每个搜索代理都通过\emph{Equation 14}移动到目标位置。非线性舒适区参数\emph{m}由\ emph {Equation 7}设置。之后，每个搜索代理通过\emph{Equation 11}以特定的概率进行$ L\acute{e}vy $航班，并生成新的位置。在更新阶段，计算新位置的适合度。如果新的适应度优于全局适应度，则新的位置可以取代旧的全球目标。如果新的适应度不比全球目标更优化，那么它就会进入跳跃阶段。在此阶段，搜索代理尝试通过\ emph {Equation 13}跳出局部最优值，并计算新的适应度。如果新的健身状况优于个人健身，新职位可以取代旧的个人职位。参数\emph{p}也由\emph{Equation 15}更新。到目前为止，循环中的一次迭代已经完成。在达到最大迭代次数之后，循环结束，并且适应度和目标位置被呈现为最终结果。 IGOA的伪代码显示为\ref{alg:IGOA}。 IGOA程序的数字框架显示为\ref{fig:procedure_IGOA}。
% In the initialization stage, the parameters are set, and the original positions of all the search agents are initialized randomly. The best target position and the corresponding fitness are also calculated in this part. The search loop starts to work in the evolution stage. Every search agent moves towards the target position by \emph{Equation 14}. The nonlinear comfort zone parameter \emph{m} is set by \emph{Equation 7}. After that, every search agent conducts $L\acute{e}vy$ flight in a particular probability by \emph{Equation 11} and a new position is generated. In the updating stage, the fitness of the new position is calculated. If the new fitness is better than the global fitness, the new position can replace the old global target. If the new fitness is not more optimal than the global target, it comes to the jumping stage. In this stage, the search agent tries to jump out of the local optimum by \emph{Equation 13} and a new fitness is calculated. If the new fitness is better than personal fitness, the new position can replace the old personal position. Parameter \emph{p} is updated by \emph{Equation 15} as well. So far, one iteration in the loop is finished. After the maximum number of iterations is reached, the loop ends, and the fitness and the target position are presented as the final result. The pseudo code of the IGOA is shown as \emph{Algorithm 1}. The figure framework of the procedure of IGOA is shown as \emph{Figure 1}.
\begin{algorithm}
    % \setstretch{1.35}
    \caption{Improved Grasshopper Optimization Algorithm}
    \label{alg:IGOA}
    
    \begin{algorithmic}[1]
    
    \State initialize the parameters
    \State initialize the swarm position with random matrix 
    \State calculate the original target fitness and mark the target position
    
    \While {$(iter < MaxIteration$ and $target fitness > destination fitness)$}
    \State set the nonlinear comfort zone parameter m by equation(6)
    % \STATE calculate $d_ij$ and $\widehat{d_ij}$ by equation(2)
    % \STATE calculate $s(d_ij)$ by equation(3)
    \State update $x_i$ by equation(13)
    \State $x_i$ conducts $L\acute{e}vy$ flight by equation(10)
    \State calculate the fitness 
    \If{current fitness is better than the target fitness}
        \State update the target fitness and the target position
    \Else
        \State$x_i$ jumps out by equation(12)
        \State calculate the fitness
        \If{current fitness is better than the personal fitness}
            \State update the personal position
        \EndIf
        \State set parameters \emph{p} by equation(14)
    \EndIf
    \EndWhile
    \State Return target fitness and target position
    \end{algorithmic}
\end{algorithm}

\graphicspath{{Img/}}
\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\linewidth]{procedure_of_IGOA.eps}\hfill\\[0.5cm]
  \caption{The figure framework of the procedure of IGOA}
  \label{fig:procedure_IGOA}
  \end{figure}
\subsection{实验结果}
\subsubsection{实验设置}
为了评估拟议的IGOA的性能，进行了一系列实验。 在这项工作中，IGOA与6个元启发式算法进行了比较，包括原始的Grasshopper优化算法（GOA），基于对立的学习GOA（OBLGOA），最近提出的三种算法，鲸鱼优化算法（WOA），蜻蜓算法（DA） 和Ant Lion Optimizer（ALO），以及经典的启发式算法，粒子群优化算法（PSO）。 将其他6种算法与IGOA相比较的参数设置为论文引用{saremi2017grasshopper，kennedy1995particle，mirjalili2016WOA，mirjalili2016dragonfly，ewees2018改进，mirjalili2015ant}。
% To evaluate the performance of the proposed IGOA, a series of experiments were conducted. In this work, IGOA was compared with 6 meta-heuristic algorithms including the original Grasshopper Optimization Algorithm (GOA), the opposition-based learning GOA (OBLGOA), three recently proposed algorithms, Whale Optimization Algorithm (WOA), Dragonfly Algorithm (DA) and Ant Lion Optimizer (ALO), and a classical heuristic algorithm, Particle Swarm Optimization (PSO). The parameters of the other 6 algorithms compared with IGOA were set as the papers \cite{saremi2017grasshopper,kennedy1995particle,mirjalili2016WOA,mirjalili2016dragonfly,ewees2018improved,mirjalili2015ant} described.
% 这里需要提一下IGOA的参数设置问题

在这一部分中，使用了29个众所周知的基准函数来测试所提出的IGOA的搜索能力。基准测试分为3种类型，可以评估算法的不同功能。在\ref{tab:unimodal_function}中列出的基准\emph{F1-F7}是单峰函数，只有一个最佳位置可以估计开发能力。在\ref{tab:multimodal_function}和\ref{tab:fixedmodal_function}中列出的基准\emph{F8-F23}是具有多个局部最优的多模函数，可以评估探索能力\ cite {saremi2017grasshopper}。在\ref{tab:composite_function}中列出的基准\emph{F24-F29}是复合函数\ cite {liang2005novel}，它在框架下组合了一些基本的测试函数，并且更复杂。他们可以评估摆脱局部最优的表现。在\ emph {表1-4}中，\emph{Dim}表示基准函数的维度，\emph{Range}是优化问题的搜索边界，$ f_min $是函数的最佳适应度。
% In this part, 29 well-known benchmark functions were used to test the search ability of the proposed IGOA. The benchmarks are divided into 3 types which can evaluate the different capability of the algorithms. Benchmarks \emph{F1-F7} listed in \emph{Table 1} are unimodal functions with only one optimal location which can estimate the ability of exploitation. Benchmarks \emph{F8-F23} listed in \emph{Table 2} and \emph{Table 3} are multimodal functions with several local optimums which can evaluate the exploration capability \cite{saremi2017grasshopper}.  Benchmarks \emph{F24-F29} listed in \emph{Table 4} are composite functions \cite{liang2005novel} which combine some basic test functions under a framework and are more complicated. They can evaluate the performance of getting out of local optimum. In \emph{Table 1-4}, \emph{Dim} represents the dimension of the benchmark functions, \emph{Range} is the search boundary of the optimization problems, and $f_min$ is the optimal fitness of the functions.

使用Matlab代码进行了与上述29个基准函数相关的一系列实验。 对于\ emph {F1-F23}，每个算法使用30个搜索代理进行500次迭代，以进行完整的搜索过程。 对于\ emph {F24-F29}，搜索过程包含100次迭代。 每个搜索过程将针对每个算法重复30次以消除意外事件，并且计算一些统计数据，例如平均值（平均值），标准偏差（标准差），最佳适合度30（最佳）和最差适合度30（最差）， 比较算法的性能。 此外，进行了Wilcoxon秩和检验，计算了\ emph {p-value}以证明结果的统计显着性。
% A series of experiments relating to the 29 benchmark functions described above were conducted with Matlab code. For \emph{F1-F23}, each algorithm was evolved for 500 iterations with 30 search agents to make a complete search process. For \emph{F24-F29}, a search process contained 100 iterations. Each search process would be repeated 30 times for every algorithm to eliminate contingency and some statistical data, such as average (avg), standard deviation (std), best fitness of 30 (best) and worst fitness of 30 (worst), was calculated to compare the performance of the algorithms. Besides, the Wilcoxon rank-sum test was conducted, and the \emph{p-value} was calculated to demonstrate the statistical significance of the results.

\begin{table}[!htbp]
    \centering
    \caption{Multimodal functions-2}
    \label{tab:fixedmodal_function}
    \small
    \renewcommand\arraystretch{2.0} 
\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
\begin{tabular}{l c c c}
    \hline
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    Function & Dim & Range & $f_{min}$ \\
    \hline
    $F_{14}(x)=(\frac{1}{500}+\sum_{j=1}^{25} \frac{1}{j+\sum_{i=1}^2 (x_i-a_{ij})^6})^{-1}$ & 2 & [-65,65]&0 \\
    \hline
    $F_{15}(x)=\sum_{i=1}^{11}[a_i-\frac{x_i(b_i^2+b_ix_2)}{b_i^2+b_ix_3+x_4}]^2$& 4 & [-5,5]&0.00030 \\
    \hline
    $F_{16}(x)=4x_1^2-2.1x_1^4+\frac{1}{3}x_1^6+x_1x_2-4x_2^2+4x_2^4$& 2 & [-5,5] & -1.0316\\
    \hline
    $F_{17}(x)=(x_2-\frac{5.1}{4\pi ^2}x_1^2+\frac{5}{\pi}x_1-6)^2+10(1-\frac{1}{8\pi})\cos x_1+10$& 2 & [-5,5] & 0.3979\\
    \hline
    \tabincell{c}{$F_{18}(x)= [1+(x_1+x_2+1)^2(19-14x_1+3x_1^2-14x_2+6x_1x_2+3x_2^2)]\times$ \\ $[30+2x_1-3x_2)^2\times(18-32x_1+12x_1^2+48x_2-36x_1x_2+27x_2^2)]$ }& 2 & [-2,2] & 3\\
    \hline
    $F_{19}(x)=-\sum_{i=1}^4c_iexp(-\sum_{j=1}^3a_{ij}(x_j-p_{ij})^2)$& 3 & [1,3] & -3.86\\
    \hline
    $F_{20}(x)=-\sum_{i=1}^4c_iexp(-\sum_{j=1}^6a_{ij}(x_j-p_{ij})^2)$& 6 & [0,1] & -3.32\\
    \hline
    $F_{21}(x)=-\sum_{i=1}^5[(X-a_i)(X-a_i)^T+c_i]^{-1}$& 4 & [0,10] & -10.1532\\
    \hline
    $F_{22}(x)=-\sum_{i=1}^7[(X-a_i)(X-a_i)^T+c_i]^{-1}$& 4 & [0,10] & -10.4028\\
    \hline
    $F_{23}(x)=-\sum_{i=1}^10[(X-a_i)(X-a_i)^T+c_i]^{-1}$& 4 & [0,10] & -10.5363\\
    \hline
  \end{tabular}
\end{table}

\begin{table}[!htbp]
    \centering
    \caption{Composite functions}
    \label{tab:composite_function}
    \scriptsize

\newcommand{\tabincell}[2]{\begin{tabular}{@{}#1@{}}#2\end{tabular}}
    \renewcommand\arraystretch{1.5} 
\begin{tabular}{l c c c}
    \hline
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    Function & Dim & Range & $f_{min}$ \\
    \hline
    \tabincell{l}{$F_{24}(CF1)$ \\$f_1,f_2,f_3,...f_{10}=Sphere Function,[\sigma_1,\sigma_2,\sigma_3,...\sigma_{10}=[1,1,1,...1]$\\$[\lambda_1,\lambda_2,\lambda_3,...\lambda_{10}]=[5/100,5/100,5/100,...5/100]$}& 30 & [-5,5]&0 \\
    \hline
    \tabincell{l}{$F_{25}(CF2)$ \\$f_1,f_2,f_3,...f_{10}=Griewank's Function,[\sigma_1,\sigma_2,\sigma_3,...\sigma_{10}=[1,1,1,...1]$\\$[\lambda_1,\lambda_2,\lambda_3,...\lambda_{10}]=[5/100,5/100,5/100,...5/100]$}& 30 & [-5,5]&0 \\
    \hline
    \tabincell{l}{$F_{26}(CF3)$ \\$f_1,f_2,f_3,...f_{10}=Griewank's Function,[\sigma_1,\sigma_2,\sigma_3,...\sigma_{10}=[1,1,1,...1]$\\$[\lambda_1,\lambda_2,\lambda_3,...\lambda_{10}]=[1,1,1,...1]$}& 30 & [-5,5]&0 \\
    \hline
    \tabincell{l}{$F_{27}(CF4)$ \\$f_1,f_2=Ackley's Function,f_3,f_4=Rastrigin's Function,$\\$f_5,f_6=Weierstrass Function,f_7,f_8=Griewank's Function,$\\$f_9,f_{10}=Sphere Function,[\sigma_1,\sigma_2,\sigma_3,...\sigma_{10}=[1,1,1,...1]$\\$[\lambda_1,\lambda_2,\lambda_3,...\lambda_{10}]=[5/32,5/32,5/32,...5/32]$}& 30 & [-5,5]&0 \\
    \hline
    \tabincell{l}{$F_{28}(CF5)$ \\$f_1,f_2=Rastrigin's Function,f_3,f_4=Weierstrass Function,$\\$f_5,f_6=Griewank's Function,f_7,f_8=Ackley's Function,$\\$f_9,f_{10}=Sphere Function,[\sigma_1,\sigma_2,\sigma_3,...\sigma_{10}=[1,1,1,...1]$\\$[\lambda_1,\lambda_2,\lambda_3,...\lambda_{10}]=[1/5,1/5,5/0.5,5/0.5,5/100,5/100,5/32,5/32,5/100,5/100]$}& 30 & [-5,5]&0 \\
    \hline
    \tabincell{l}{$F_{29}(CF6)$ \\$f_1,f_2=Rastrigin's Function,f_3,f_4=Weierstrass Function,$\\$f_5,f_6=Griewank's Function,f_7,f_8=Ackley's Function,$\\$f_9,f_{10}=Sphere Function$\\$[\sigma_1,\sigma_2,\sigma_3,...\sigma_{10}=[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]$\\$[\lambda_1,\lambda_2,\lambda_3,...\lambda_{10}]=[0.1*1/5,0.2*1/5,0.3*5/0.5,0.4*5/0.5,0.5*5/100,$\\$0.6*5/100,0.7*5/32,0.8*5/32,0.9*5/100,1*5/100]$}& 30 & [-5,5]&0 \\
    \hline
  \end{tabular}

\end{table}
\subsubsection{实验结果}

\subsubsection{wilcoxon符号秩检验}
\subsubsection{收敛图}

\section{任务调度问题}
\subsection{问题描述}
\subsection{任务调度模型}
\subsection{实验结果}


\section{本章小结}